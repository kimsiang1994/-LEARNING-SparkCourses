{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the findspark library to locate spark on our local machine\n",
    "import findspark\n",
    "findspark.init(r'C:\\spark\\spark-3.5.0-bin-hadoop3')\n",
    "import pyspark # only run this after findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "data=[(\"Z\", 1),(\"A\", 20),(\"B\", 30),(\"C\", 40),(\"B\", 30),(\"B\", 60)]\n",
    "\n",
    "inputRDD = spark.sparkContext.parallelize(data)\n",
    "  \n",
    "listRdd = spark.sparkContext.parallelize([1,2,3,4,5,3,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seqOp is a lambda function that specifies the sequence operation. In this case, it's a lambda function that takes two arguments x and y and returns their sum (x + y).\n",
    "\n",
    "combOp is a lambda function that specifies the combine operation. Similarly, it takes two arguments x and y and returns their sum (x + y).\n",
    "\n",
    "agg is a variable that stores the result of the aggregate operation.\n",
    "\n",
    "listRdd is assumed to be an RDD that you want to aggregate.\n",
    "\n",
    "The aggregate action is applied to the listRdd RDD. It takes three arguments:\n",
    "\n",
    "The initial value for aggregation (0 in this case).\n",
    "The sequence operation (seqOp), which is applied to elements within each partition of the RDD.\n",
    "The combine operation (combOp), which is used to combine results from different partitions.\n",
    "The result of the aggregation is stored in the agg variable.\n",
    "\n",
    "Finally, print(agg) is used to print the result, which is 20.\n",
    "\n",
    "The aggregation operation sums up all the elements in the RDD listRdd by applying the seqOp function within each partition and then combining the results using the combOp function. In this case, the elements in listRdd are assumed to be integers, and the result is the sum of all these integers, which is 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#aggregate\n",
    "seqOp = (lambda x, y: x + y)\n",
    "combOp = (lambda x, y: x + y)\n",
    "agg=listRdd.aggregate(0, seqOp, combOp)\n",
    "print(agg) # output 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seqOp2 is a lambda function that specifies the sequence operation. It takes two arguments, x and y, where x is a tuple of two values (x[0], x[1]), and y is an element from the RDD. The lambda function returns a tuple where the first element is the sum of x[0] and y (the running total), and the second element is x[1] + 1 (the running count of elements).\n",
    "\n",
    "combOp2 is a lambda function that specifies the combine operation. It takes two arguments, x and y, where both x and y are tuples with two values each. The lambda function returns a tuple where the first element is the sum of the first elements of x and y (the total sum), and the second element is the sum of the second elements of x and y (the total count).\n",
    "\n",
    "agg2 is a variable that stores the result of the aggregate operation.\n",
    "\n",
    "listRdd is assumed to be an RDD that you want to aggregate.\n",
    "\n",
    "The aggregate action is applied to the listRdd RDD. It takes three arguments:\n",
    "\n",
    "The initial value for aggregation, which is a tuple (0, 0) in this case, where the first element is the initial sum (0) and the second element is the initial count (0).\n",
    "The sequence operation (seqOp2), which is applied to elements within each partition of the RDD.\n",
    "The combine operation (combOp2), which is used to combine results from different partitions.\n",
    "The result of the aggregation is stored in the agg2 variable.\n",
    "\n",
    "Finally, print(agg2) is used to print the result, which is (20, 7). The first element of the tuple is the sum of all the elements in the RDD, and the second element is the count of elements in the RDD.\n",
    "\n",
    "So, the result (20, 7) indicates that the sum of elements in listRdd is 20, and there are a total of 7 elements in the RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 7)\n"
     ]
    }
   ],
   "source": [
    "#aggregate 2\n",
    "seqOp2 = (lambda x, y: (x[0] + y, x[1] + 1))\n",
    "combOp2 = (lambda x, y: (x[0] + y[0], x[1] + y[1]))\n",
    "agg2=listRdd.aggregate((0, 0), seqOp2, combOp2)\n",
    "print(agg2) # output (20,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "agg2=listRdd.treeAggregate(0,seqOp, combOp)\n",
    "print(agg2) # output 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from operator import add imports the add function, which is a built-in Python function for addition. In this case, it will be used as the associative function for aggregation.\n",
    "\n",
    "foldRes is a variable that will store the result of the fold operation.\n",
    "\n",
    "listRdd is assumed to be an RDD containing integers that you want to sum.\n",
    "\n",
    "The fold operation is applied to the listRdd RDD. It takes two arguments:\n",
    "\n",
    "The initial value for aggregation, which is 0 in this case.\n",
    "The associative function, which is add (the addition function) in this case.\n",
    "The fold operation iterates through the elements in the RDD and aggregates them using the associative function. In this case, it adds all the integers in the RDD starting from the initial value of 0.\n",
    "\n",
    "The result of the aggregation is stored in the foldRes variable.\n",
    "\n",
    "Finally, print(foldRes) is used to print the result, which is 20. This indicates that the sum of all the elements in listRdd is 20.\n",
    "\n",
    "So, the fold operation is a more general aggregation operation that allows you to specify an initial value and an associative function for the aggregation. In your case, it's used to calculate the sum of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#fold\n",
    "from operator import add\n",
    "foldRes=listRdd.fold(0, add)\n",
    "print(foldRes) # output 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PySpark, the reduce operation is used to aggregate the elements of an RDD using a specified function, in this case, the add function for addition. Your code is using the reduce operation to calculate the sum of the elements in listRdd. Here's how the code works:\n",
    "\n",
    "redRes is a variable that will store the result of the reduce operation.\n",
    "\n",
    "listRdd is assumed to be an RDD containing integers that you want to sum.\n",
    "\n",
    "The reduce operation is applied to the listRdd RDD with the add function as its argument. The add function is a built-in Python function for addition.\n",
    "\n",
    "The reduce operation iterates through the elements in the RDD and aggregates them using the add function. It starts with the first element, adds it to the next element, and continues this process until all elements are aggregated into a single result.\n",
    "\n",
    "The result of the aggregation is stored in the redRes variable.\n",
    "\n",
    "Finally, print(redRes) is used to print the result, which is 20. This indicates that the sum of all the elements in listRdd is 20.\n",
    "\n",
    "So, the reduce operation is a way to reduce an RDD to a single value by iteratively applying a function to the elements. In your case, it's used to calculate the sum of the elements using the add function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#reduce\n",
    "redRes=listRdd.reduce(add)\n",
    "print(redRes) # output 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add is a lambda function that specifies the aggregation operation. In this case, it's a lambda function that takes two arguments x and y and returns their sum (x + y).\n",
    "\n",
    "redRes is a variable that will store the result of the treeReduce operation.\n",
    "\n",
    "listRdd is assumed to be an RDD containing integers that you want to sum.\n",
    "\n",
    "The treeReduce operation is applied to the listRdd RDD with the add function as its argument.\n",
    "\n",
    "The treeReduce operation aggregates the elements in the RDD using a tree-based aggregation algorithm. This algorithm is more efficient for larger RDDs because it reduces the amount of data transferred between partitions.\n",
    "\n",
    "The result of the aggregation is stored in the redRes variable.\n",
    "\n",
    "Finally, print(redRes) is used to print the result, which is 20. This indicates that the sum of all the elements in listRdd is 20.\n",
    "\n",
    "In summary, treeReduce is a more efficient version of reduce for larger RDDs, as it leverages a tree-based aggregation algorithm to optimize the computation and reduce data transfer overhead in a distributed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "#treeReduce. This is similar to reduce\n",
    "add = lambda x, y: x + y\n",
    "redRes=listRdd.treeReduce(add)\n",
    "print(redRes) # output 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data is a variable that will store the result of the collect operation.\n",
    "\n",
    "listRdd is assumed to be an RDD containing elements that you want to collect.\n",
    "\n",
    "The collect action is applied to the listRdd RDD. When you call collect(), it retrieves all the elements from all partitions of the RDD and collects them into a list in the driver program.\n",
    "\n",
    "The result, which is a list containing all the elements from the RDD, is stored in the data variable.\n",
    "\n",
    "Finally, print(data) is used to print the contents of the data list, which will display all the elements from the listRdd RDD.\n",
    "\n",
    "It's important to note that using collect can be memory-intensive, especially if the RDD is large, because it brings all the data to the driver program. In practice, you should use collect with caution, and only when you have a good reason to bring the data to the driver, as it can lead to out-of-memory errors if the RDD is too large."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 3, 2]\n"
     ]
    }
   ],
   "source": [
    "#Collect\n",
    "data = listRdd.collect()\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listRdd is assumed to be an RDD containing elements for which you want to estimate the count.\n",
    "\n",
    "listRdd.countApprox(1200) is calling the countApprox method on the RDD listRdd with a maximum acceptable relative standard deviation of 1200. This means that the method will return an approximate count of the elements with a relative standard deviation of up to 1200 (which controls the precision of the estimate).\n",
    "\n",
    "The result of the countApprox method is then converted to a string and concatenated with the string \"countApprox : \" using the + operator.\n",
    "\n",
    "Finally, the entire string is printed using the print function.\n",
    "\n",
    "The output of this code will be a string that includes the estimated count of elements in listRdd with the specified relative standard deviation. For example, if the estimated count is 1000, the output would be something like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count : 7\n",
      "countApprox : 6\n",
      "countApproxDistinct : 5\n",
      "countApproxDistinct : 5\n",
      "countByValue :  defaultdict(<class 'int'>, {1: 1, 2: 2, 3: 2, 4: 1, 5: 1})\n",
      "first :  1\n",
      "first :  ('Z', 1)\n",
      "top : [5, 4]\n",
      "top : [('Z', 1), ('C', 40)]\n",
      "min :  1\n",
      "min :  ('A', 20)\n",
      "max :  5\n",
      "max :  ('Z', 1)\n",
      "take : [1, 2]\n",
      "takeOrdered : [1, 2]\n",
      "take : [2, 5, 2, 3, 1, 4, 3]\n"
     ]
    }
   ],
   "source": [
    "#count, countApprox, countApproxDistinct\n",
    "print(\"Count : \"+str(listRdd.count()))\n",
    "#Output: Count : 20\n",
    "print(\"countApprox : \"+str(listRdd.countApprox(1200)))\n",
    "#Output: countApprox : (final: [7.000, 7.000])\n",
    "print(\"countApproxDistinct : \"+str(listRdd.countApproxDistinct()))\n",
    "#Output: countApproxDistinct : 5\n",
    "print(\"countApproxDistinct : \"+str(inputRDD.countApproxDistinct()))\n",
    "#Output: countApproxDistinct : 5\n",
    "\n",
    "#countByValue, countByValueApprox\n",
    "print(\"countByValue :  \"+str(listRdd.countByValue()))\n",
    "\n",
    "\n",
    "#first\n",
    "print(\"first :  \"+str(listRdd.first()))\n",
    "#Output: first :  1\n",
    "print(\"first :  \"+str(inputRDD.first()))\n",
    "#Output: first :  (Z,1)\n",
    "\n",
    "#top\n",
    "print(\"top : \"+str(listRdd.top(2)))\n",
    "#Output: take : 5,4\n",
    "print(\"top : \"+str(inputRDD.top(2)))\n",
    "#Output: take : (Z,1),(C,40)\n",
    "\n",
    "#min\n",
    "print(\"min :  \"+str(listRdd.min()))\n",
    "#Output: min :  1\n",
    "print(\"min :  \"+str(inputRDD.min()))\n",
    "#Output: min :  (A,20)  \n",
    "\n",
    "#max\n",
    "print(\"max :  \"+str(listRdd.max()))\n",
    "#Output: max :  5\n",
    "print(\"max :  \"+str(inputRDD.max()))\n",
    "#Output: max :  (Z,1)\n",
    "\n",
    "#take, takeOrdered, takeSample\n",
    "print(\"take : \"+str(listRdd.take(2)))\n",
    "#Output: take : 1,2\n",
    "print(\"takeOrdered : \"+ str(listRdd.takeOrdered(2)))\n",
    "#Output: takeOrdered : 1,2\n",
    "print(\"take : \"+str(listRdd.takeSample(withReplacement=False, num=10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
