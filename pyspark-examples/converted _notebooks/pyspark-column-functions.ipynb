{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the findspark library to locate spark on our local machine\n",
    "import findspark\n",
    "findspark.init(r'C:\\spark\\spark-3.5.0-bin-hadoop3')\n",
    "import pyspark # only run this after findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data=[(\"James\",\"Bond\",\"100\",None),\n",
    "      (\"Ann\",\"Varsa\",\"200\",'F'),\n",
    "      (\"Tom Cruise\",\"XXX\",\"400\",''),\n",
    "      (\"Tom Brand\",None,\"400\",'M')] \n",
    "columns=[\"fname\",\"lname\",\"id\",\"gender\"]\n",
    "df=spark.createDataFrame(data,columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.select(...): This code selects specific columns from the DataFrame and applies transformations to them.\n",
    "\n",
    "df.fname.alias(\"first_name\"): This renames the \"fname\" column to \"first_name\" using the alias method. The alias method is used to provide a new name for the selected column.\n",
    "\n",
    "df.lname.alias(\"last_name\"): This renames the \"lname\" column to \"last_name\" using the alias method, similar to the previous line.\n",
    "\n",
    "expr(\" fname ||','|| lname\").alias(\"fullName\"): This part of the code creates a new column called \"fullName\" by using the expr function. Inside the expr, it concatenates the values from the \"fname\" and \"lname\" columns along with a comma separator (,).\n",
    "\n",
    ".show(): Finally, the show method is called on the resulting DataFrame to display its contents in the console.\n",
    "\n",
    "So, the overall purpose of this code is to transform the original DataFrame df by renaming the \"fname\" and \"lname\" columns to \"first_name\" and \"last_name,\" respectively, and creating a new column \"fullName\" that contains the concatenation of \"fname\" and \"lname\" values separated by a comma. The result is displayed in tabular format using the show method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+--------------+\n",
      "|first_name|last_name|      fullName|\n",
      "+----------+---------+--------------+\n",
      "|     James|     Bond|    James,Bond|\n",
      "|       Ann|    Varsa|     Ann,Varsa|\n",
      "|Tom Cruise|      XXX|Tom Cruise,XXX|\n",
      "| Tom Brand|     NULL|          NULL|\n",
      "+----------+---------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#alias\n",
    "from pyspark.sql.functions import expr\n",
    "df.select(df.fname.alias(\"first_name\"), \\\n",
    "          df.lname.alias(\"last_name\"), \\\n",
    "          expr(\" fname ||','|| lname\").alias(\"fullName\") \\\n",
    "   ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|       Ann|Varsa|200|     F|\n",
      "|     James| Bond|100|  NULL|\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#asc, desc\n",
    "df.sort(df.fname.asc()).show()\n",
    "df.sort(df.fname.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- fname: string (nullable = true)\n",
      " |-- id: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#cast\n",
    "df.select(df.fname,df.id.cast(\"int\")).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+------+\n",
      "|fname|lname| id|gender|\n",
      "+-----+-----+---+------+\n",
      "|James| Bond|100|  NULL|\n",
      "|  Ann|Varsa|200|     F|\n",
      "+-----+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#between\n",
    "df.filter(df.id.between(100,300)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#contains\n",
    "df.filter(df.fname.contains(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "| Tom Brand| NULL|400|     M|\n",
      "+----------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#startswith, endswith()\n",
    "df.filter(df.fname.startswith(\"T\")).show()\n",
    "df.filter(df.fname.endswith(\"Cruise\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+---+------+\n",
      "|    fname|lname| id|gender|\n",
      "+---------+-----+---+------+\n",
      "|Tom Brand| NULL|400|     M|\n",
      "+---------+-----+---+------+\n",
      "\n",
      "+----------+-----+---+------+\n",
      "|     fname|lname| id|gender|\n",
      "+----------+-----+---+------+\n",
      "|     James| Bond|100|  NULL|\n",
      "|       Ann|Varsa|200|     F|\n",
      "|Tom Cruise|  XXX|400|      |\n",
      "+----------+-----+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#isNull & isNotNull\n",
    "df.filter(df.lname.isNull()).show()\n",
    "df.filter(df.lname.isNotNull()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+---+\n",
      "|     fname|lname| id|\n",
      "+----------+-----+---+\n",
      "|Tom Cruise|  XXX|400|\n",
      "| Tom Brand| NULL|400|\n",
      "+----------+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#like , rlike\n",
    "df.select(df.fname,df.lname,df.id) \\\n",
    "  .filter(df.fname.like(\"%Tom%\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df.fname.substr(1, 2): This part of the code uses the substr function to extract a substring from the \"fname\" column. The substr function takes two arguments: the starting position (1 in this case) and the length of the substring (2 in this case). This means it will start from the first character and take the next two characters from the \"fname\" column.\n",
    "\n",
    ".alias(\"substr\"): After extracting the substring, the alias method is used to rename the resulting column to \"substr.\" This provides a new name for the selected column.\n",
    "\n",
    ".show(): Finally, the show method is called on the resulting DataFrame to display its contents in the console.\n",
    "\n",
    "So, the overall purpose of this code is to create a new DataFrame that contains a column called \"substr,\" which contains substrings of length 2 extracted from the \"fname\" column of the original DataFrame df. The result is displayed in tabular format using the show method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|substr|\n",
      "+------+\n",
      "|    Ja|\n",
      "|    An|\n",
      "|    To|\n",
      "|    To|\n",
      "+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#substr\n",
    "df.select(df.fname.substr(1,2).alias(\"substr\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+----------+\n",
      "|     fname|lname|new_gender|\n",
      "+----------+-----+----------+\n",
      "|     James| Bond|      NULL|\n",
      "|       Ann|Varsa|    Female|\n",
      "|Tom Cruise|  XXX|          |\n",
      "| Tom Brand| NULL|      Male|\n",
      "+----------+-----+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#when & otherwise\n",
    "from pyspark.sql.functions import when\n",
    "df.select(df.fname,df.lname,when(df.gender==\"M\",\"Male\") \\\n",
    "              .when(df.gender==\"F\",\"Female\") \\\n",
    "              .when(df.gender==None ,\"\") \\\n",
    "              .otherwise(df.gender).alias(\"new_gender\") \\\n",
    "    ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+\n",
      "|fname|lname| id|\n",
      "+-----+-----+---+\n",
      "|James| Bond|100|\n",
      "|  Ann|Varsa|200|\n",
      "+-----+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#isin\n",
    "li=[\"100\",\"200\"]\n",
    "df.select(df.fname,df.lname,df.id) \\\n",
    "  .filter(df.id.isin(li)) \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The provided PySpark code defines a custom schema for a DataFrame using the StructType and related data types (StructField, StringType, ArrayType, and MapType). Let's break down what this schema represents:\n",
    "\n",
    "StructType([...]): This is the top-level schema definition, and it represents the structure of a DataFrame with multiple columns.\n",
    "\n",
    "StructField('name', StructType([...]), True): This defines a column named \"name\" with a nested structure. It's a StructType itself with two nested fields: \"fname\" and \"lname,\" both of type StringType(). The True argument indicates that this column allows null values.\n",
    "\n",
    "StructField('languages', ArrayType(StringType()), True): This defines a column named \"languages\" as an array of strings. The ArrayType(StringType()) represents an array where each element is a string. The True argument indicates that this column allows null values.\n",
    "\n",
    "StructField('properties', MapType(StringType(), StringType()), True): This defines a column named \"properties\" as a map of strings to strings. The MapType(StringType(), StringType()) represents a map where both keys and values are strings. The True argument indicates that this column allows null values.\n",
    "\n",
    "In summary, this schema defines a DataFrame with three columns:\n",
    "\n",
    "\"name\": A nested structure with two fields, \"fname\" and \"lname,\" both of type string.\n",
    "\"languages\": An array of strings.\n",
    "\"properties\": A map where both keys and values are strings.\n",
    "This schema can be used as a blueprint when creating a PySpark DataFrame to ensure that the DataFrame has the specified structure and data types for its columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: struct (nullable = true)\n",
      " |    |-- fname: string (nullable = true)\n",
      " |    |-- lname: string (nullable = true)\n",
      " |-- languages: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- properties: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n",
      "+-----------------+---------------+--------------------+\n",
      "|             name|      languages|          properties|\n",
      "+-----------------+---------------+--------------------+\n",
      "|    {James, Bond}|     [Java, C#]|{eye -> brown, ha...|\n",
      "|     {Ann, Varsa}| [.NET, Python]|{eye -> black, ha...|\n",
      "|   {Tom Cruise, }|[Python, Scala]|{eye -> grey, hai...|\n",
      "|{Tom Brand, NULL}|   [Perl, Ruby]|{eye -> blue, hai...|\n",
      "+-----------------+---------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType,StructField,StringType,ArrayType,MapType\n",
    "data=[((\"James\",\"Bond\"),[\"Java\",\"C#\"],{'hair':'black','eye':'brown'}),\n",
    "      ((\"Ann\",\"Varsa\"),[\".NET\",\"Python\"],{'hair':'brown','eye':'black'}),\n",
    "      ((\"Tom Cruise\",\"\"),[\"Python\",\"Scala\"],{'hair':'red','eye':'grey'}),\n",
    "      ((\"Tom Brand\",None),[\"Perl\",\"Ruby\"],{'hair':'black','eye':'blue'})]\n",
    "\n",
    "schema = StructType([\n",
    "        StructField('name', StructType([\n",
    "            StructField('fname', StringType(), True),\n",
    "            StructField('lname', StringType(), True)])),\n",
    "        StructField('languages', ArrayType(StringType()),True),\n",
    "        StructField('properties', MapType(StringType(),StringType()),True)\n",
    "     ])\n",
    "df=spark.createDataFrame(data,schema)\n",
    "df.printSchema()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|languages[1]|\n",
      "+------------+\n",
      "|          C#|\n",
      "|      Python|\n",
      "|       Scala|\n",
      "|        Ruby|\n",
      "+------------+\n",
      "\n",
      "+----------------+\n",
      "|properties[hair]|\n",
      "+----------------+\n",
      "|           black|\n",
      "|           brown|\n",
      "|             red|\n",
      "|           black|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getItem()\n",
    "df.select(df.languages.getItem(1)).show()\n",
    "\n",
    "df.select(df.properties.getItem(\"hair\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|properties[hair]|\n",
      "+----------------+\n",
      "|           black|\n",
      "|           brown|\n",
      "|             red|\n",
      "|           black|\n",
      "+----------------+\n",
      "\n",
      "+----------+\n",
      "|name.fname|\n",
      "+----------+\n",
      "|     James|\n",
      "|       Ann|\n",
      "|Tom Cruise|\n",
      "| Tom Brand|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getField from Struct or Map\n",
    "df.select(df.properties.getField(\"hair\")).show()\n",
    "\n",
    "df.select(df.name.getField(\"fname\")).show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
