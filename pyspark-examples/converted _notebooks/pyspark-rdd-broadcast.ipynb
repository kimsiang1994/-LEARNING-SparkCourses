{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the findspark library to locate spark on our local machine\n",
    "import findspark\n",
    "findspark.init(r'C:\\spark\\spark-3.5.0-bin-hadoop3')\n",
    "import pyspark # only run this after findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "states = {\"NY\":\"New York\", \"CA\":\"California\", \"FL\":\"Florida\"}\n",
    "broadcastStates = spark.sparkContext.broadcast(states)\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "broadcastStates is likely a broadcast variable created in a Spark application. Broadcast variables allow you to efficiently share read-only data across multiple tasks in a distributed computation, making it accessible to all worker nodes without the need to transmit the data over the network multiple times.\n",
    "\n",
    "broadcastStates.value is used to access the value associated with the broadcastStates variable. In this context, it's expected that broadcastStates contains a dictionary-like object where keys correspond to state codes and values correspond to state names or other information.\n",
    "\n",
    "code is the argument passed to the state_convert function. It is expected to be a state code (e.g., a two-letter abbreviation like \"CA\" for California).\n",
    "\n",
    "Inside the function, broadcastStates.value[code] retrieves the value associated with the provided code from the broadcast variable, effectively looking up the state name or information associated with that code.\n",
    "\n",
    "For example, if you call state_convert(\"CA\"), it would return the corresponding state name or information associated with the state code \"CA\" from the broadcastStates dictionary-like object.\n",
    "\n",
    "This approach is often used in Spark applications to efficiently share reference data (like state codes and their corresponding names) across tasks running on different worker nodes in a distributed environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('James', 'Smith', 'USA', 'California'), ('Michael', 'Rose', 'USA', 'New York'), ('Robert', 'Williams', 'USA', 'California'), ('Maria', 'Jones', 'USA', 'Florida')]\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.parallelize(data)\n",
    "\n",
    "def state_convert(code):\n",
    "    return broadcastStates.value[code]\n",
    "\n",
    "result = rdd.map(lambda x: (x[0],x[1],x[2],state_convert(x[3]))).collect()\n",
    "print(result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
