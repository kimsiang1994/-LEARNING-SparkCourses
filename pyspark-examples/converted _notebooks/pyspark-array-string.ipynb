{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we use the findspark library to locate spark on our local machine\n",
    "import findspark\n",
    "findspark.init(r'C:\\spark\\spark-3.5.0-bin-hadoop3')\n",
    "import pyspark # only run this after findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[1]\") \\\n",
    "                    .appName('SparkByExamples.com') \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- currentState: string (nullable = true)\n",
      "\n",
      "+----------------+------------------+------------+\n",
      "|name            |languagesAtSchool |currentState|\n",
      "+----------------+------------------+------------+\n",
      "|James,,Smith    |[Java, Scala, C++]|CA          |\n",
      "|Michael,Rose,   |[Spark, Java, C++]|NJ          |\n",
      "|Robert,,Williams|[CSharp, VB]      |NV          |\n",
      "+----------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns = [\"name\",\"languagesAtSchool\",\"currentState\"]\n",
    "data = [(\"James,,Smith\",[\"Java\",\"Scala\",\"C++\"],\"CA\"), \\\n",
    "    (\"Michael,Rose,\",[\"Spark\",\"Java\",\"C++\"],\"NJ\"), \\\n",
    "    (\"Robert,,Williams\",[\"CSharp\",\"VB\"],\"NV\")]\n",
    "\n",
    "df = spark.createDataFrame(data=data,schema=columns)\n",
    "df.printSchema()\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df.withColumn(\"languagesAtSchool\", concat_ws(\",\", col(\"languagesAtSchool\"))):\n",
    "It creates a new DataFrame df2 by adding a new column called \"languagesAtSchool.\"\n",
    "The values for the new column \"languagesAtSchool\" are generated using the concat_ws function.\n",
    "concat_ws stands for \"concatenate with separator.\" It is used to concatenate the values of one or more columns into a single column, separated by a specified delimiter (in this case, a comma \",\").\n",
    "col(\"languagesAtSchool\") selects the \"languagesAtSchool\" column from the original DataFrame df.\n",
    "So, the code takes the values in the \"languagesAtSchool\" column from the original DataFrame df, concatenates them into a single string with comma separators, and assigns this concatenated string as the values for the new \"languagesAtSchool\" column in the DataFrame df2. This can be useful for formatting or reshaping data within your DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- languagesAtSchool: string (nullable = false)\n",
      " |-- currentState: string (nullable = true)\n",
      "\n",
      "+----------------+-----------------+------------+\n",
      "|name            |languagesAtSchool|currentState|\n",
      "+----------------+-----------------+------------+\n",
      "|James,,Smith    |Java,Scala,C++   |CA          |\n",
      "|Michael,Rose,   |Spark,Java,C++   |NJ          |\n",
      "|Robert,,Williams|CSharp,VB        |NV          |\n",
      "+----------------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat_ws\n",
    "df2 = df.withColumn(\"languagesAtSchool\",\n",
    "   concat_ws(\",\",col(\"languagesAtSchool\")))\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+------------+\n",
      "|name            |languagesAtSchool|currentState|\n",
      "+----------------+-----------------+------------+\n",
      "|James,,Smith    |Java,Scala,C++   |CA          |\n",
      "|Michael,Rose,   |Spark,Java,C++   |NJ          |\n",
      "|Robert,,Williams|CSharp,VB        |NV          |\n",
      "+----------------+-----------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.createOrReplaceTempView(\"ARRAY_STRING\")\n",
    "spark.sql(\"select name, concat_ws(',',languagesAtSchool) as languagesAtSchool,currentState from ARRAY_STRING\").show(truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
